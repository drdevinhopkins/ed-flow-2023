{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99479887",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'chronos-forecasting>=2.0' 'pandas[pyarrow]' 'matplotlib' 'python-dotenv' --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284c711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244a5c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1218253951.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load the Chronos-2 pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# GPU recommended for faster inference, but CPU is also supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m pipeline: Chronos2Pipeline = BaseChronosPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;34m\"amazon/chronos-2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chronos/base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_s3_download, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Trying to load unknown pipeline class: {pipeline_class_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         return class_.from_pretrained(  # type: ignore[attr-defined]\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chronos/chronos2/pipeline.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChronos2Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5046\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5047\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5048\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5049\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_hqq_or_quark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5431\u001b[0m             \u001b[0mexpanded_device_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5432\u001b[0;31m             \u001b[0mcaching_allocator_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_device_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5434\u001b[0m         \u001b[0;31m# Prepare and compatabilize arguments for serial and parallel shard loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mcaching_allocator_warmup\u001b[0;34m(model, expanded_device_map, hf_quantizer)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m             \u001b[0mtorch_accelerator_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch_accelerator_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m             \u001b[0mdevice_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_accelerator_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_get_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m             \u001b[0;31m# Allow up to (max device memory - 1.2 GiB) in resource-constrained hardware configurations. Trying to reserve more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;34mr\"\"\"Return the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use only 1 GPU if available\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"HF_TOKEN\"] =  ...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from chronos import BaseChronosPipeline, Chronos2Pipeline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load the Chronos-2 pipeline\n",
    "# GPU recommended for faster inference, but CPU is also supported\n",
    "pipeline: Chronos2Pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-2\", \n",
    "    # device_map=\"cuda\"\n",
    "        device_map=\"cpu\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1058a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7ffec652-6a7f-483b-8e4c-2f79f9d71e5c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>INFLOW_STRETCHER</th>\n",
       "      <th>Infl_Stretcher_cum</th>\n",
       "      <th>INFLOW_AMBULATORY</th>\n",
       "      <th>Infl_Ambulatory_cum</th>\n",
       "      <th>Inflow_Total</th>\n",
       "      <th>Inflow_Cum_Total</th>\n",
       "      <th>INFLOW_AMBULANCES</th>\n",
       "      <th>Infl_Ambulances_cum</th>\n",
       "      <th>FLS</th>\n",
       "      <th>...</th>\n",
       "      <th>RAZ_IMCONS_MORE4H</th>\n",
       "      <th>RAZ_XRAY_MORE2H</th>\n",
       "      <th>RAZ_CT_MORE2H1</th>\n",
       "      <th>PSYCH1</th>\n",
       "      <th>PSYCH_WAITINGADM</th>\n",
       "      <th>total_tbs</th>\n",
       "      <th>vert_tbs</th>\n",
       "      <th>pod_tbs</th>\n",
       "      <th>overflow</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42861</th>\n",
       "      <td>2025-11-25 06:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>jgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42862</th>\n",
       "      <td>2025-11-25 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>jgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42863</th>\n",
       "      <td>2025-11-25 08:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>jgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42864</th>\n",
       "      <td>2025-11-25 09:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>jgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42865</th>\n",
       "      <td>2025-11-25 10:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>jgh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ffec652-6a7f-483b-8e4c-2f79f9d71e5c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7ffec652-6a7f-483b-8e4c-2f79f9d71e5c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7ffec652-6a7f-483b-8e4c-2f79f9d71e5c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                       ds  INFLOW_STRETCHER  Infl_Stretcher_cum  \\\n",
       "42861 2025-11-25 06:00:00                 5                  20   \n",
       "42862 2025-11-25 07:00:00                 1                  21   \n",
       "42863 2025-11-25 08:00:00                 4                  25   \n",
       "42864 2025-11-25 09:00:00                11                  36   \n",
       "42865 2025-11-25 10:00:00                 7                  43   \n",
       "\n",
       "       INFLOW_AMBULATORY  Infl_Ambulatory_cum  Inflow_Total  Inflow_Cum_Total  \\\n",
       "42861                  1                    7             6                27   \n",
       "42862                  1                    8             2                29   \n",
       "42863                  2                   10             6                35   \n",
       "42864                  9                   19            20                55   \n",
       "42865                  8                   27            15                70   \n",
       "\n",
       "       INFLOW_AMBULANCES  Infl_Ambulances_cum  FLS  ...  RAZ_IMCONS_MORE4H  \\\n",
       "42861                  1                    3    0  ...                  1   \n",
       "42862                  0                    3    0  ...                  1   \n",
       "42863                  2                    5    0  ...                  1   \n",
       "42864                  0                    5    0  ...                  1   \n",
       "42865                  3                    8    0  ...                  1   \n",
       "\n",
       "       RAZ_XRAY_MORE2H  RAZ_CT_MORE2H1  PSYCH1  PSYCH_WAITINGADM  total_tbs  \\\n",
       "42861                0               0      14                 9         14   \n",
       "42862                0               0      14                 9         13   \n",
       "42863                0               0      15                 9         12   \n",
       "42864                0               0      15                 9         11   \n",
       "42865                0               0      16                 9         15   \n",
       "\n",
       "       vert_tbs  pod_tbs  overflow   id  \n",
       "42861        10        4        10  jgh  \n",
       "42862         9        4        10  jgh  \n",
       "42863        10        2         9  jgh  \n",
       "42864        10        1         9  jgh  \n",
       "42865        12        3         9  jgh  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/scl/fi/s83jig4zews1xz7vhezui/allDataWithCalculatedColumns.csv?rlkey=9mm4zwaugxyj2r4ooyd39y4nl&raw=1')\n",
    "df.ds = pd.to_datetime(df.ds, errors=\"coerce\")\n",
    "df['id']='jgh'\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d072b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from IPython.display import clear_output\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TS_COL = \"ds\"\n",
    "TARGETS = ['total_tbs']\n",
    "\n",
    "df = df.copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Snap to exact hours (lowercase 'h' to avoid FutureWarning)\n",
    "df[TS_COL] = df[TS_COL].dt.floor(\"h\")\n",
    "\n",
    "# Sort + dedupe\n",
    "df = df.sort_values([ID_COL, TS_COL]).drop_duplicates([ID_COL, TS_COL], keep=\"last\")\n",
    "\n",
    "def regularize_hourly(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex each group's timestamps to strict hourly and fill gaps.\n",
    "    Works whether the grouping column is present or omitted (include_groups=False).\n",
    "    \"\"\"\n",
    "    # The group key (id) is available as g.name; if ID_COL exists, prefer it.\n",
    "    sid = g[ID_COL].iloc[0] if ID_COL in g.columns else g.name\n",
    "\n",
    "    g = g.sort_values(TS_COL)\n",
    "    full_idx = pd.date_range(g[TS_COL].min(), g[TS_COL].max(), freq=\"h\")\n",
    "    g = g.set_index(TS_COL).reindex(full_idx)\n",
    "    g.index.name = TS_COL\n",
    "\n",
    "    # restore id (constant for the whole group)\n",
    "    g[ID_COL] = sid\n",
    "\n",
    "    # numeric + fill for targets\n",
    "    for col in TARGETS:\n",
    "        if col in g.columns:\n",
    "            g[col] = pd.to_numeric(g[col], errors=\"coerce\").ffill().bfill()\n",
    "    return g.reset_index()\n",
    "\n",
    "# Call apply with include_groups=False if supported; else fall back\n",
    "gb = df.groupby(ID_COL, group_keys=False)\n",
    "try:\n",
    "    df = gb.apply(regularize_hourly, include_groups=False)\n",
    "except TypeError:\n",
    "    # older pandas without include_groups\n",
    "    df = gb.apply(regularize_hourly)\n",
    "\n",
    "# Assert truly hourly (accept 'h' and 'H')\n",
    "g = df[df[ID_COL] == \"jgh\"].sort_values(TS_COL)\n",
    "freq = pd.infer_freq(g[TS_COL])\n",
    "if not freq:\n",
    "    raise ValueError(\"No inferable frequency after regularization.\")\n",
    "if to_offset(freq).name.lower() != \"h\":\n",
    "    # extra check independent of infer_freq\n",
    "    diffs = g[TS_COL].diff().dropna()\n",
    "    bad = g.loc[diffs != pd.Timedelta(hours=1), TS_COL].head(10).tolist()\n",
    "    raise ValueError(f\"Non-1h gaps remain around: {bad}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a646a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-355ef02d-4725-4c66-93c1-fadeac04284e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ds</th>\n",
       "      <th>target_name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 11:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>19.753437</td>\n",
       "      <td>15.721951</td>\n",
       "      <td>19.753437</td>\n",
       "      <td>23.749315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 12:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>25.029087</td>\n",
       "      <td>18.912363</td>\n",
       "      <td>25.029087</td>\n",
       "      <td>31.435581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 13:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>32.323257</td>\n",
       "      <td>23.889149</td>\n",
       "      <td>32.323257</td>\n",
       "      <td>40.106224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 14:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>35.319305</td>\n",
       "      <td>25.685329</td>\n",
       "      <td>35.319305</td>\n",
       "      <td>44.433418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 15:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>38.139164</td>\n",
       "      <td>27.355043</td>\n",
       "      <td>38.139164</td>\n",
       "      <td>47.595650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 16:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>41.407425</td>\n",
       "      <td>29.648672</td>\n",
       "      <td>41.407425</td>\n",
       "      <td>51.472557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 17:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>38.304260</td>\n",
       "      <td>25.579184</td>\n",
       "      <td>38.304260</td>\n",
       "      <td>49.484268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 18:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>35.639309</td>\n",
       "      <td>23.134516</td>\n",
       "      <td>35.639309</td>\n",
       "      <td>48.234520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 19:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>33.396877</td>\n",
       "      <td>21.155796</td>\n",
       "      <td>33.396877</td>\n",
       "      <td>45.446354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 20:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>30.512127</td>\n",
       "      <td>18.702192</td>\n",
       "      <td>30.512127</td>\n",
       "      <td>43.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 21:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>28.452940</td>\n",
       "      <td>16.801353</td>\n",
       "      <td>28.452940</td>\n",
       "      <td>40.912033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 22:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>25.760960</td>\n",
       "      <td>14.880566</td>\n",
       "      <td>25.760960</td>\n",
       "      <td>38.078781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-25 23:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>23.368204</td>\n",
       "      <td>13.578991</td>\n",
       "      <td>23.368204</td>\n",
       "      <td>35.170021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 00:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>23.435823</td>\n",
       "      <td>13.552259</td>\n",
       "      <td>23.435823</td>\n",
       "      <td>34.930840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 01:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>23.101324</td>\n",
       "      <td>13.808272</td>\n",
       "      <td>23.101324</td>\n",
       "      <td>34.092354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 02:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>21.511028</td>\n",
       "      <td>12.838673</td>\n",
       "      <td>21.511028</td>\n",
       "      <td>32.171532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 03:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>18.925058</td>\n",
       "      <td>10.411164</td>\n",
       "      <td>18.925058</td>\n",
       "      <td>29.014940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 04:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>16.575449</td>\n",
       "      <td>8.644957</td>\n",
       "      <td>16.575449</td>\n",
       "      <td>26.587191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 05:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>14.149110</td>\n",
       "      <td>6.568707</td>\n",
       "      <td>14.149110</td>\n",
       "      <td>23.748980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 06:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>13.121649</td>\n",
       "      <td>6.118155</td>\n",
       "      <td>13.121649</td>\n",
       "      <td>22.243893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 07:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>13.836173</td>\n",
       "      <td>6.716290</td>\n",
       "      <td>13.836173</td>\n",
       "      <td>23.146902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 08:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>18.238997</td>\n",
       "      <td>9.811564</td>\n",
       "      <td>18.238997</td>\n",
       "      <td>28.383160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 09:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>14.993173</td>\n",
       "      <td>7.165451</td>\n",
       "      <td>14.993173</td>\n",
       "      <td>24.500605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jgh</td>\n",
       "      <td>2025-11-26 10:00:00</td>\n",
       "      <td>total_tbs</td>\n",
       "      <td>17.566792</td>\n",
       "      <td>8.987195</td>\n",
       "      <td>17.566792</td>\n",
       "      <td>27.546638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-355ef02d-4725-4c66-93c1-fadeac04284e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-355ef02d-4725-4c66-93c1-fadeac04284e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-355ef02d-4725-4c66-93c1-fadeac04284e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     id                  ds target_name  predictions        0.1        0.5  \\\n",
       "0   jgh 2025-11-25 11:00:00   total_tbs    19.753437  15.721951  19.753437   \n",
       "1   jgh 2025-11-25 12:00:00   total_tbs    25.029087  18.912363  25.029087   \n",
       "2   jgh 2025-11-25 13:00:00   total_tbs    32.323257  23.889149  32.323257   \n",
       "3   jgh 2025-11-25 14:00:00   total_tbs    35.319305  25.685329  35.319305   \n",
       "4   jgh 2025-11-25 15:00:00   total_tbs    38.139164  27.355043  38.139164   \n",
       "5   jgh 2025-11-25 16:00:00   total_tbs    41.407425  29.648672  41.407425   \n",
       "6   jgh 2025-11-25 17:00:00   total_tbs    38.304260  25.579184  38.304260   \n",
       "7   jgh 2025-11-25 18:00:00   total_tbs    35.639309  23.134516  35.639309   \n",
       "8   jgh 2025-11-25 19:00:00   total_tbs    33.396877  21.155796  33.396877   \n",
       "9   jgh 2025-11-25 20:00:00   total_tbs    30.512127  18.702192  30.512127   \n",
       "10  jgh 2025-11-25 21:00:00   total_tbs    28.452940  16.801353  28.452940   \n",
       "11  jgh 2025-11-25 22:00:00   total_tbs    25.760960  14.880566  25.760960   \n",
       "12  jgh 2025-11-25 23:00:00   total_tbs    23.368204  13.578991  23.368204   \n",
       "13  jgh 2025-11-26 00:00:00   total_tbs    23.435823  13.552259  23.435823   \n",
       "14  jgh 2025-11-26 01:00:00   total_tbs    23.101324  13.808272  23.101324   \n",
       "15  jgh 2025-11-26 02:00:00   total_tbs    21.511028  12.838673  21.511028   \n",
       "16  jgh 2025-11-26 03:00:00   total_tbs    18.925058  10.411164  18.925058   \n",
       "17  jgh 2025-11-26 04:00:00   total_tbs    16.575449   8.644957  16.575449   \n",
       "18  jgh 2025-11-26 05:00:00   total_tbs    14.149110   6.568707  14.149110   \n",
       "19  jgh 2025-11-26 06:00:00   total_tbs    13.121649   6.118155  13.121649   \n",
       "20  jgh 2025-11-26 07:00:00   total_tbs    13.836173   6.716290  13.836173   \n",
       "21  jgh 2025-11-26 08:00:00   total_tbs    18.238997   9.811564  18.238997   \n",
       "22  jgh 2025-11-26 09:00:00   total_tbs    14.993173   7.165451  14.993173   \n",
       "23  jgh 2025-11-26 10:00:00   total_tbs    17.566792   8.987195  17.566792   \n",
       "\n",
       "          0.9  \n",
       "0   23.749315  \n",
       "1   31.435581  \n",
       "2   40.106224  \n",
       "3   44.433418  \n",
       "4   47.595650  \n",
       "5   51.472557  \n",
       "6   49.484268  \n",
       "7   48.234520  \n",
       "8   45.446354  \n",
       "9   43.052414  \n",
       "10  40.912033  \n",
       "11  38.078781  \n",
       "12  35.170021  \n",
       "13  34.930840  \n",
       "14  34.092354  \n",
       "15  32.171532  \n",
       "16  29.014940  \n",
       "17  26.587191  \n",
       "18  23.748980  \n",
       "19  22.243893  \n",
       "20  23.146902  \n",
       "21  28.383160  \n",
       "22  24.500605  \n",
       "23  27.546638  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "pred_df = pipeline.predict_df(\n",
    "    df,\n",
    "    prediction_length=24,\n",
    "    quantile_levels=[0.1, 0.5, 0.9],\n",
    "    id_column=ID_COL,\n",
    "    timestamp_column=TS_COL,\n",
    "    target=TARGETS,\n",
    ")\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e405ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the 8-hour forecast: 37.92843462412088\n"
     ]
    }
   ],
   "source": [
    "#lelt's perform cross-validation to evaluate our model's performance\n",
    "#start with df.ds ending on 2025-01-01 08:00:00 and predict the next 8 hours\n",
    "#then compare with actuals\n",
    "cutoff_date = pd.Timestamp(\"2025-01-01 08:00:00\")\n",
    "history_df = df[df[TS_COL] <= cutoff_date]\n",
    "forecast_df = pipeline.predict_df(\n",
    "    history_df,\n",
    "    prediction_length=8,\n",
    "    quantile_levels=[0.5],\n",
    "    id_column=ID_COL,\n",
    "    timestamp_column=TS_COL,\n",
    "    target=TARGETS,\n",
    ")\n",
    "# Merge forecasts with actuals\n",
    "actuals_df = df[(df[TS_COL] > cutoff_date) & (df[TS_COL] <= cutoff_date + pd.Timedelta(hours=8))]\n",
    "merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "# Calculate RMSE for the predictions\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(\n",
    "    merged_df['total_tbs'],\n",
    "    merged_df['predictions']\n",
    ")\n",
    "print(f\"RMSE for the 8-hour forecast: {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca441be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efe021f03ca4188ab006670af9e1903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.4963992215985\n",
      "42.994789491468055\n",
      "327.08347856883347\n",
      "60.68348983573014\n",
      "18.60393970670475\n",
      "146.21347762184814\n",
      "16.335154826307644\n",
      "34.34325724865221\n",
      "121.41309804913408\n",
      "11.840215114093553\n",
      "42.619944982237485\n",
      "50.9739136718963\n",
      "55.21406163546408\n",
      "117.35878362394487\n",
      "24.68718893283858\n",
      "37.3123610247676\n",
      "117.84111315494829\n",
      "62.31707148425312\n",
      "19.56962495198877\n",
      "133.80616573396856\n",
      "63.62354144688152\n",
      "62.59166608917076\n",
      "49.357523911707176\n",
      "15.663567579581468\n",
      "69.6897081606553\n",
      "51.52362971958928\n",
      "93.5806795242197\n",
      "35.48292807676171\n",
      "118.57451550070505\n",
      "13.71307589887681\n",
      "208.52038020967575\n",
      "3.1508102989082545\n",
      "97.09296838291277\n",
      "9.88177953711147\n",
      "55.16259507627001\n",
      "11.193362669328508\n",
      "9.743788514928838\n",
      "12.588659648528392\n",
      "170.71569699996917\n",
      "15.137724285215427\n",
      "33.170903200249995\n",
      "20.956503264008916\n",
      "22.325393279591026\n",
      "181.86535522524946\n",
      "15.672107035089539\n",
      "130.45207771543164\n",
      "186.25399282183582\n",
      "6.42702484785309\n",
      "7.211903344056054\n",
      "16.164402460513884\n",
      "27.86681043197632\n",
      "81.18996351684928\n",
      "58.112869771365695\n",
      "20.36766856916529\n",
      "27.234619729407314\n",
      "15.599138791417317\n",
      "22.52403117193444\n",
      "14.65292882992344\n",
      "53.8771039565454\n",
      "113.9443516714241\n",
      "172.05460203155883\n",
      "42.42762226196055\n",
      "106.05025939052939\n",
      "70.39696248585915\n",
      "37.56912708221989\n",
      "8.662556627209597\n",
      "67.52548442560601\n",
      "5.25588696382556\n",
      "26.027307591982662\n",
      "25.457190873043146\n",
      "22.0847501412145\n",
      "31.73852620459047\n",
      "51.33609270168063\n",
      "27.362183610466673\n",
      "18.349551790720852\n",
      "43.63748289615887\n",
      "4.246670789627842\n",
      "5.924085391224253\n",
      "25.87610592607109\n",
      "29.22155566408992\n",
      "79.27900678977767\n",
      "24.921885875995713\n",
      "59.08933943026159\n",
      "222.70714320630486\n",
      "14.655162428299377\n",
      "30.850551758103506\n",
      "169.09617237806924\n",
      "14.851600039169398\n",
      "10.277308897951116\n",
      "68.42172478431576\n",
      "48.48010654668178\n",
      "51.369853892646915\n",
      "16.410382378184977\n",
      "51.39988423933437\n",
      "107.92598996612742\n",
      "16.661651090654686\n",
      "30.446312151437724\n",
      "48.18903533474713\n",
      "18.10568940631788\n",
      "15.519684539080117\n",
      "49.79826813336956\n",
      "18.896887012202114\n",
      "11.110837664985297\n",
      "37.002823411131885\n",
      "3.2824917674424796\n",
      "36.98593959239952\n",
      "15.505456929197862\n",
      "19.52308771941898\n",
      "12.938732621213148\n",
      "61.791133691270375\n",
      "24.653321999466243\n",
      "255.0761369987572\n",
      "26.035020893099045\n",
      "40.85668582492872\n",
      "72.29496809446755\n",
      "81.52910447176828\n",
      "19.12130218774837\n",
      "19.186955700716226\n",
      "11.578524084827222\n",
      "21.75291114775837\n",
      "24.33717201565969\n",
      "19.294727322484505\n",
      "152.0584842697408\n",
      "55.38127646503017\n",
      "65.39714029382412\n",
      "115.18023820002429\n",
      "19.351628399262154\n",
      "10.944655239609801\n",
      "186.31424326345586\n",
      "30.36629515204777\n",
      "29.586404841595936\n",
      "54.49273777397275\n",
      "78.24279573421109\n",
      "3.0906428441753633\n",
      "18.554677771237493\n",
      "42.01918678137099\n",
      "2.413485189134917\n",
      "35.64029794228827\n",
      "76.03929807416262\n",
      "4.080417068902989\n",
      "19.80517319750561\n",
      "31.80427506160254\n",
      "25.57375999655187\n",
      "49.59532737224845\n",
      "18.63282254253727\n",
      "13.151355463070558\n",
      "71.67758509895975\n",
      "21.479890845299906\n",
      "99.26204287502196\n",
      "36.96475089976957\n",
      "38.682196839432436\n",
      "140.0107527863006\n",
      "49.21722885573217\n",
      "55.5918977669844\n",
      "14.688535351011978\n",
      "14.132535330333212\n",
      "46.470654709646624\n",
      "9.93953932063323\n",
      "126.08413456130575\n",
      "15.67370704077075\n",
      "16.49177363577587\n",
      "108.9394052005232\n",
      "19.23135089623247\n",
      "188.03957132969663\n",
      "26.45572386022377\n",
      "66.75422332259905\n",
      "21.72148185152855\n",
      "33.0272577750452\n",
      "64.51224135404391\n",
      "55.29313652110022\n",
      "15.183039767059654\n",
      "51.22703503173716\n",
      "52.08560234316201\n",
      "46.16095995692831\n",
      "16.26674881961162\n",
      "11.707470879784978\n",
      "47.067367689428465\n",
      "63.91896207543323\n",
      "69.86809378782254\n",
      "64.16942859204755\n",
      "152.5083328830956\n",
      "49.30743018036992\n",
      "91.22035197532114\n",
      "67.2754104649348\n",
      "19.785008230328458\n",
      "53.82233118634258\n",
      "38.33851181575619\n",
      "21.34310948774737\n",
      "59.770083628657176\n",
      "100.90733012832243\n",
      "19.64061249205679\n",
      "59.44430122262338\n",
      "41.43026258318923\n",
      "6.493170160380487\n",
      "106.4030905543732\n",
      "20.117065287825426\n",
      "27.728600939693933\n",
      "37.63386296124736\n",
      "100.69546857712612\n",
      "37.51212026768644\n",
      "143.33444029810153\n",
      "25.32937272812387\n",
      "124.14325253122024\n",
      "14.819616726766071\n",
      "12.183677383780378\n",
      "12.893494358417684\n",
      "87.02650479649992\n",
      "72.54997208050463\n",
      "21.59835510083485\n",
      "39.69093590798548\n",
      "26.477649690204544\n",
      "4.894246107916388\n",
      "54.77036482347967\n",
      "18.30830079346515\n",
      "13.90452312395928\n",
      "19.75883299173438\n",
      "16.525678776330096\n",
      "60.460108232980474\n",
      "56.43114413282865\n",
      "16.72715193827753\n",
      "25.6127257574708\n",
      "36.22371363697039\n",
      "284.6756748558696\n",
      "97.75484469049343\n",
      "34.47632809082097\n",
      "61.4934145150396\n",
      "110.26729184581427\n",
      "6.307644662075745\n",
      "12.537595032630179\n",
      "25.18671151213175\n",
      "88.65251464090898\n",
      "138.89432400541864\n",
      "19.134399545738233\n",
      "49.97491641495117\n",
      "56.87706289361586\n",
      "127.12712469364033\n",
      "118.89410842650068\n",
      "15.900174944327318\n",
      "70.5860074857178\n",
      "153.4411383768138\n",
      "37.400869526229144\n",
      "17.482719235593322\n",
      "46.4994832251823\n",
      "8.40680262797423\n",
      "37.681297496870684\n",
      "99.25561126643925\n",
      "26.849422549023984\n",
      "45.96065729529755\n",
      "94.16639539419748\n",
      "53.35112341601052\n",
      "55.91478704449082\n",
      "28.210098440527872\n",
      "11.679818761543174\n",
      "27.52408467762507\n",
      "32.55248673644928\n",
      "21.966731837250336\n",
      "146.46719584190578\n",
      "75.97153247782308\n",
      "73.02903222387522\n",
      "34.237587648062345\n",
      "17.67492051380259\n",
      "55.24846696902705\n",
      "20.41443818124344\n",
      "6.10447819491219\n",
      "22.995810367879585\n",
      "11.720737551434468\n",
      "208.184359889834\n",
      "7.379099507726551\n",
      "12.37808504417444\n",
      "95.53441361680461\n",
      "12.56934448432321\n",
      "49.75343542404153\n",
      "69.88488467439765\n",
      "32.48128812536834\n",
      "16.09772890292561\n",
      "10.68576826137405\n",
      "20.422910361958202\n",
      "15.806792468986714\n",
      "49.137957787857886\n",
      "42.79540567008189\n",
      "21.753639387437488\n",
      "9.05772286656429\n",
      "41.00461029245889\n",
      "45.735587526924064\n",
      "25.969805450744843\n",
      "15.66200054337014\n",
      "47.010598704253425\n",
      "184.0036567488355\n",
      "18.163550546593797\n",
      "14.426163003564398\n",
      "13.717259624600501\n",
      "18.760075649419832\n",
      "26.37757517631917\n",
      "59.83078738979748\n",
      "42.64690041216363\n",
      "111.84427353483034\n",
      "160.49686829576012\n",
      "46.19701709011815\n",
      "70.46475561697798\n",
      "65.56567746300107\n",
      "105.93466157323792\n",
      "69.9404967624705\n",
      "54.071251672641324\n",
      "15.39855837639243\n",
      "36.07176812157559\n",
      "23.90092911044576\n",
      "35.65813584233638\n",
      "133.7748612002315\n",
      "230.79636918457254\n",
      "53.496816213270904\n",
      "24.6359598533204\n",
      "6.55943617411458\n",
      "89.32337141832613\n",
      "197.97913299919674\n",
      "13.494919376395046\n",
      "77.99598897896522\n",
      "Average RMSE over the period: 53.488969128799745\n"
     ]
    }
   ],
   "source": [
    "#now use tqdm to iterate through a new forecast every following day starting at 2025-01-01 always at 8am and average out the RMSEs\n",
    "from tqdm.notebook import tqdm\n",
    "rmse_list = []\n",
    "start_date = pd.Timestamp(\"2025-01-01 16:00:00\")\n",
    "end_date = df[TS_COL].max() - pd.Timedelta(hours=8)\n",
    "# end_date = pd.Timestamp(\"2025-01-05 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    # print(history_df.ds.max())\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    rmse_list.append(rmse)\n",
    "    print(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "average_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Average RMSE over the period: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "235d69ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2108db4d473642abb84d1ce37562b7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE by day of week:\n",
      "Wednesday: 41.38582932147818\n",
      "Thursday: 95.91189453069525\n",
      "Friday: 54.82910380477245\n",
      "Saturday: 70.59074537012046\n",
      "Sunday: 63.84156222594706\n",
      "Monday: 64.8229408294746\n",
      "Tuesday: 68.85372658078583\n"
     ]
    }
   ],
   "source": [
    "#I want to know the average RMSE by day of week (e.g., is the model worse on mondays than on fridays?)\n",
    "import collections\n",
    "rmse_by_day = collections.defaultdict(list)\n",
    "start_date = pd.Timestamp(\"2025-01-01 08:00:00\")\n",
    "end_date = pd.Timestamp(\"2025-04-01 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    day_of_week = start_date.day_name()\n",
    "    rmse_by_day[day_of_week].append(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "# Calculate average RMSE by day of week\n",
    "average_rmse_by_day = {day: sum(rmses) / len(rmses) for day, rmses in rmse_by_day.items()}\n",
    "print(\"Average RMSE by day of week:\")\n",
    "for day, avg_rmse in average_rmse_by_day.items():\n",
    "    print(f\"{day}: {avg_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e59914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE over the period: 78.45709604316224\n"
     ]
    }
   ],
   "source": [
    "#add day of the week as a feature and see if it improves performance\n",
    "df['day_of_week'] = df[TS_COL].dt.dayofweek\n",
    "\n",
    "#now use tqdm to iterate through a new forecast every following day starting at 2025-01-01 always at 8am and average out the RMSEs\n",
    "from tqdm.notebook import tqdm\n",
    "rmse_list = []\n",
    "start_date = pd.Timestamp(\"2025-01-01 08:00:00\")\n",
    "# end_date = df[TS_COL].max() - pd.Timedelta(hours=8)\n",
    "end_date = pd.Timestamp(\"2025-02-01 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    print(start_date)\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    rmse_list.append(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "    #clear output\n",
    "    clear_output(wait=True)\n",
    "average_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Average RMSE over the period: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aeca9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c5068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE over the period: 78.64947186187389\n"
     ]
    }
   ],
   "source": [
    "#add holidays as a feature and see if it improves performance\n",
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "def add_holiday_flags(\n",
    "    df: pd.DataFrame,\n",
    "    ts_col: str = \"ds\",\n",
    "    local_tz: str = \"America/Montreal\",\n",
    "    observed: bool = True,\n",
    "    include_names: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds boolean columns:\n",
    "      â€¢ is_qc_holiday       â€” QuÃ©bec public holiday (CA-QC)\n",
    "      â€¢ is_jewish_holiday   â€” Israeli public/Jewish holiday (IL)\n",
    "    Optionally adds:\n",
    "      â€¢ qc_holiday_name\n",
    "      â€¢ jewish_holiday_name\n",
    "\n",
    "    Notes:\n",
    "      â€¢ Holiday checks are date-based (00:00â€“24:00 local calendar date),\n",
    "        not sundown-to-sundown observance.\n",
    "      â€¢ NaT timestamps are ignored gracefully.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # 1) Parse to datetime\n",
    "    out[ts_col] = pd.to_datetime(out[ts_col], errors=\"coerce\")\n",
    "\n",
    "    # 2) Get the calendar DATE to use for holiday lookup\n",
    "    #    - If tz-aware: convert to Montreal then take .date\n",
    "    #    - If naive: assume values already represent local Montreal wall-clock; just take .date\n",
    "    if getattr(out[ts_col].dt, \"tz\", None) is not None:\n",
    "        dates_for_calendar = out[ts_col].dt.tz_convert(local_tz).dt.date\n",
    "    else:\n",
    "        dates_for_calendar = out[ts_col].dt.date\n",
    "\n",
    "    # 3) Build a SAFE integer year range for the holiday objects\n",
    "    years_series = pd.Series(dates_for_calendar)\n",
    "    years_series = years_series.dropna().map(lambda d: int(pd.Timestamp(d).year))\n",
    "    if years_series.empty:\n",
    "        raise ValueError(\"No valid datetimes found to extract holiday years.\")\n",
    "    years = list(range(int(years_series.min()), int(years_series.max()) + 1))\n",
    "\n",
    "    # 4) Construct holiday calendars\n",
    "    qc_holidays = holidays.Canada(subdiv=\"QC\", years=years, observed=observed)\n",
    "    il_holidays = holidays.Israel(years=years, observed=observed)\n",
    "\n",
    "    # 5) Flag membership\n",
    "    out[\"is_qc_holiday\"] = [ (d in qc_holidays) if pd.notna(pd.Timestamp(d)) else False\n",
    "                             for d in dates_for_calendar ]\n",
    "    # out[\"is_jewish_holiday\"] = [ (d in il_holidays) if pd.notna(pd.Timestamp(d)) else False\n",
    "    #                              for d in dates_for_calendar ]\n",
    "\n",
    "    if include_names:\n",
    "        out[\"qc_holiday_name\"] = [ qc_holidays.get(d, \"\") if pd.notna(pd.Timestamp(d)) else \"\"\n",
    "                                   for d in dates_for_calendar ]\n",
    "        out[\"jewish_holiday_name\"] = [ il_holidays.get(d, \"\") if pd.notna(pd.Timestamp(d)) else \"\"\n",
    "                                       for d in dates_for_calendar ]\n",
    "\n",
    "    return out\n",
    "\n",
    "df = pd.read_csv('https://www.dropbox.com/scl/fi/s83jig4zews1xz7vhezui/allDataWithCalculatedColumns.csv?rlkey=9mm4zwaugxyj2r4ooyd39y4nl&raw=1')\n",
    "df.ds = pd.to_datetime(df.ds, errors=\"coerce\")\n",
    "df['id']='jgh'\n",
    "df = add_holiday_flags(df, ts_col=TS_COL, include_names=False)\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TS_COL = \"ds\"\n",
    "TARGETS = ['total_tbs']\n",
    "\n",
    "df = df.copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Snap to exact hours (lowercase 'h' to avoid FutureWarning)\n",
    "df[TS_COL] = df[TS_COL].dt.floor(\"h\")\n",
    "\n",
    "# Sort + dedupe\n",
    "df = df.sort_values([ID_COL, TS_COL]).drop_duplicates([ID_COL, TS_COL], keep=\"last\")\n",
    "\n",
    "def regularize_hourly(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex each group's timestamps to strict hourly and fill gaps.\n",
    "    Works whether the grouping column is present or omitted (include_groups=False).\n",
    "    \"\"\"\n",
    "    # The group key (id) is available as g.name; if ID_COL exists, prefer it.\n",
    "    sid = g[ID_COL].iloc[0] if ID_COL in g.columns else g.name\n",
    "\n",
    "    g = g.sort_values(TS_COL)\n",
    "    full_idx = pd.date_range(g[TS_COL].min(), g[TS_COL].max(), freq=\"h\")\n",
    "    g = g.set_index(TS_COL).reindex(full_idx)\n",
    "    g.index.name = TS_COL\n",
    "\n",
    "    # restore id (constant for the whole group)\n",
    "    g[ID_COL] = sid\n",
    "\n",
    "    # numeric + fill for targets\n",
    "    for col in TARGETS:\n",
    "        if col in g.columns:\n",
    "            g[col] = pd.to_numeric(g[col], errors=\"coerce\").ffill().bfill()\n",
    "    return g.reset_index()\n",
    "\n",
    "# Call apply with include_groups=False if supported; else fall back\n",
    "gb = df.groupby(ID_COL, group_keys=False)\n",
    "try:\n",
    "    df = gb.apply(regularize_hourly, include_groups=False)\n",
    "except TypeError:\n",
    "    # older pandas without include_groups\n",
    "    df = gb.apply(regularize_hourly)\n",
    "\n",
    "# Assert truly hourly (accept 'h' and 'H')\n",
    "g = df[df[ID_COL] == \"jgh\"].sort_values(TS_COL)\n",
    "freq = pd.infer_freq(g[TS_COL])\n",
    "if not freq:\n",
    "    raise ValueError(\"No inferable frequency after regularization.\")\n",
    "if to_offset(freq).name.lower() != \"h\":\n",
    "    # extra check independent of infer_freq\n",
    "    diffs = g[TS_COL].diff().dropna()\n",
    "    bad = g.loc[diffs != pd.Timedelta(hours=1), TS_COL].head(10).tolist()\n",
    "    raise ValueError(f\"Non-1h gaps remain around: {bad}\")\n",
    "\n",
    "#now use tqdm to iterate through a new forecast every following day starting at 2025-01-01 always at 8am and average out the RMSEs\n",
    "from tqdm.notebook import tqdm\n",
    "rmse_list = []\n",
    "start_date = pd.Timestamp(\"2025-01-01 08:00:00\")\n",
    "# end_date = df[TS_COL].max() - pd.Timedelta(hours=8)\n",
    "end_date = pd.Timestamp(\"2025-02-01 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    print(start_date)\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    rmse_list.append(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "    #clear output\n",
    "    clear_output(wait=True)\n",
    "average_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Average RMSE over the period: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4bead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE over the period: 78.5571038847945\n"
     ]
    }
   ],
   "source": [
    "#add holidays as a feature and see if it improves performance\n",
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "def add_holiday_flags(\n",
    "    df: pd.DataFrame,\n",
    "    ts_col: str = \"ds\",\n",
    "    local_tz: str = \"America/Montreal\",\n",
    "    observed: bool = True,\n",
    "    include_names: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds boolean columns:\n",
    "      â€¢ is_qc_holiday       â€” QuÃ©bec public holiday (CA-QC)\n",
    "      â€¢ is_jewish_holiday   â€” Israeli public/Jewish holiday (IL)\n",
    "    Optionally adds:\n",
    "      â€¢ qc_holiday_name\n",
    "      â€¢ jewish_holiday_name\n",
    "\n",
    "    Notes:\n",
    "      â€¢ Holiday checks are date-based (00:00â€“24:00 local calendar date),\n",
    "        not sundown-to-sundown observance.\n",
    "      â€¢ NaT timestamps are ignored gracefully.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # 1) Parse to datetime\n",
    "    out[ts_col] = pd.to_datetime(out[ts_col], errors=\"coerce\")\n",
    "\n",
    "    # 2) Get the calendar DATE to use for holiday lookup\n",
    "    #    - If tz-aware: convert to Montreal then take .date\n",
    "    #    - If naive: assume values already represent local Montreal wall-clock; just take .date\n",
    "    if getattr(out[ts_col].dt, \"tz\", None) is not None:\n",
    "        dates_for_calendar = out[ts_col].dt.tz_convert(local_tz).dt.date\n",
    "    else:\n",
    "        dates_for_calendar = out[ts_col].dt.date\n",
    "\n",
    "    # 3) Build a SAFE integer year range for the holiday objects\n",
    "    years_series = pd.Series(dates_for_calendar)\n",
    "    years_series = years_series.dropna().map(lambda d: int(pd.Timestamp(d).year))\n",
    "    if years_series.empty:\n",
    "        raise ValueError(\"No valid datetimes found to extract holiday years.\")\n",
    "    years = list(range(int(years_series.min()), int(years_series.max()) + 1))\n",
    "\n",
    "    # 4) Construct holiday calendars\n",
    "    qc_holidays = holidays.Canada(subdiv=\"QC\", years=years, observed=observed)\n",
    "    il_holidays = holidays.Israel(years=years, observed=observed)\n",
    "\n",
    "    # 5) Flag membership\n",
    "    # out[\"is_qc_holiday\"] = [ (d in qc_holidays) if pd.notna(pd.Timestamp(d)) else False\n",
    "    #                          for d in dates_for_calendar ]\n",
    "    out[\"is_jewish_holiday\"] = [ (d in il_holidays) if pd.notna(pd.Timestamp(d)) else False\n",
    "                                 for d in dates_for_calendar ]\n",
    "\n",
    "    if include_names:\n",
    "        out[\"qc_holiday_name\"] = [ qc_holidays.get(d, \"\") if pd.notna(pd.Timestamp(d)) else \"\"\n",
    "                                   for d in dates_for_calendar ]\n",
    "        out[\"jewish_holiday_name\"] = [ il_holidays.get(d, \"\") if pd.notna(pd.Timestamp(d)) else \"\"\n",
    "                                       for d in dates_for_calendar ]\n",
    "\n",
    "    return out\n",
    "\n",
    "df = pd.read_csv('https://www.dropbox.com/scl/fi/s83jig4zews1xz7vhezui/allDataWithCalculatedColumns.csv?rlkey=9mm4zwaugxyj2r4ooyd39y4nl&raw=1')\n",
    "df.ds = pd.to_datetime(df.ds, errors=\"coerce\")\n",
    "df['id']='jgh'\n",
    "df = add_holiday_flags(df, ts_col=TS_COL, include_names=False)\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TS_COL = \"ds\"\n",
    "TARGETS = ['total_tbs']\n",
    "\n",
    "df = df.copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Snap to exact hours (lowercase 'h' to avoid FutureWarning)\n",
    "df[TS_COL] = df[TS_COL].dt.floor(\"h\")\n",
    "\n",
    "# Sort + dedupe\n",
    "df = df.sort_values([ID_COL, TS_COL]).drop_duplicates([ID_COL, TS_COL], keep=\"last\")\n",
    "\n",
    "def regularize_hourly(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex each group's timestamps to strict hourly and fill gaps.\n",
    "    Works whether the grouping column is present or omitted (include_groups=False).\n",
    "    \"\"\"\n",
    "    # The group key (id) is available as g.name; if ID_COL exists, prefer it.\n",
    "    sid = g[ID_COL].iloc[0] if ID_COL in g.columns else g.name\n",
    "\n",
    "    g = g.sort_values(TS_COL)\n",
    "    full_idx = pd.date_range(g[TS_COL].min(), g[TS_COL].max(), freq=\"h\")\n",
    "    g = g.set_index(TS_COL).reindex(full_idx)\n",
    "    g.index.name = TS_COL\n",
    "\n",
    "    # restore id (constant for the whole group)\n",
    "    g[ID_COL] = sid\n",
    "\n",
    "    # numeric + fill for targets\n",
    "    for col in TARGETS:\n",
    "        if col in g.columns:\n",
    "            g[col] = pd.to_numeric(g[col], errors=\"coerce\").ffill().bfill()\n",
    "    return g.reset_index()\n",
    "\n",
    "# Call apply with include_groups=False if supported; else fall back\n",
    "gb = df.groupby(ID_COL, group_keys=False)\n",
    "try:\n",
    "    df = gb.apply(regularize_hourly, include_groups=False)\n",
    "except TypeError:\n",
    "    # older pandas without include_groups\n",
    "    df = gb.apply(regularize_hourly)\n",
    "\n",
    "# Assert truly hourly (accept 'h' and 'H')\n",
    "g = df[df[ID_COL] == \"jgh\"].sort_values(TS_COL)\n",
    "freq = pd.infer_freq(g[TS_COL])\n",
    "if not freq:\n",
    "    raise ValueError(\"No inferable frequency after regularization.\")\n",
    "if to_offset(freq).name.lower() != \"h\":\n",
    "    # extra check independent of infer_freq\n",
    "    diffs = g[TS_COL].diff().dropna()\n",
    "    bad = g.loc[diffs != pd.Timedelta(hours=1), TS_COL].head(10).tolist()\n",
    "    raise ValueError(f\"Non-1h gaps remain around: {bad}\")\n",
    "\n",
    "#now use tqdm to iterate through a new forecast every following day starting at 2025-01-01 always at 8am and average out the RMSEs\n",
    "from tqdm.notebook import tqdm\n",
    "rmse_list = []\n",
    "start_date = pd.Timestamp(\"2025-01-01 08:00:00\")\n",
    "# end_date = df[TS_COL].max() - pd.Timedelta(hours=8)\n",
    "end_date = pd.Timestamp(\"2025-02-01 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    print(start_date)\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    rmse_list.append(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "    #clear output\n",
    "    clear_output(wait=True)\n",
    "average_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Average RMSE over the period: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b38289d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE over the period: 57.56830870363711\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/scl/fi/s83jig4zews1xz7vhezui/allDataWithCalculatedColumns.csv?rlkey=9mm4zwaugxyj2r4ooyd39y4nl&raw=1')\n",
    "df.ds = pd.to_datetime(df.ds, errors=\"coerce\")\n",
    "df['id']='jgh'\n",
    "\n",
    "hourly_shifts = pd.read_csv('https://www.dropbox.com/scl/fi/1ap6anzn5q13lcykh3idn/hourly_shifts.csv?rlkey=ue7nnfmrxij8keku8cgsrveo8&raw=1')\n",
    "hourly_shifts.ds = pd.to_datetime(hourly_shifts.ds, errors=\"coerce\")\n",
    "#replace all NaNs with NoMD in hourly_shifts\n",
    "hourly_shifts = hourly_shifts.fillna('NoMD')\n",
    "\n",
    "df = pd.merge(df, hourly_shifts, on='ds', how='left')\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TS_COL = \"ds\"\n",
    "TARGETS = ['total_tbs']\n",
    "\n",
    "df = df.copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Snap to exact hours (lowercase 'h' to avoid FutureWarning)\n",
    "df[TS_COL] = df[TS_COL].dt.floor(\"h\")\n",
    "\n",
    "# Sort + dedupe\n",
    "df = df.sort_values([ID_COL, TS_COL]).drop_duplicates([ID_COL, TS_COL], keep=\"last\")\n",
    "\n",
    "def regularize_hourly(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex each group's timestamps to strict hourly and fill gaps.\n",
    "    Works whether the grouping column is present or omitted (include_groups=False).\n",
    "    \"\"\"\n",
    "    # The group key (id) is available as g.name; if ID_COL exists, prefer it.\n",
    "    sid = g[ID_COL].iloc[0] if ID_COL in g.columns else g.name\n",
    "\n",
    "    g = g.sort_values(TS_COL)\n",
    "    full_idx = pd.date_range(g[TS_COL].min(), g[TS_COL].max(), freq=\"h\")\n",
    "    g = g.set_index(TS_COL).reindex(full_idx)\n",
    "    g.index.name = TS_COL\n",
    "\n",
    "    # restore id (constant for the whole group)\n",
    "    g[ID_COL] = sid\n",
    "\n",
    "    # numeric + fill for targets\n",
    "    for col in TARGETS:\n",
    "        if col in g.columns:\n",
    "            g[col] = pd.to_numeric(g[col], errors=\"coerce\").ffill().bfill()\n",
    "    return g.reset_index()\n",
    "\n",
    "# Call apply with include_groups=False if supported; else fall back\n",
    "gb = df.groupby(ID_COL, group_keys=False)\n",
    "try:\n",
    "    df = gb.apply(regularize_hourly, include_groups=False)\n",
    "except TypeError:\n",
    "    # older pandas without include_groups\n",
    "    df = gb.apply(regularize_hourly)\n",
    "\n",
    "# Assert truly hourly (accept 'h' and 'H')\n",
    "g = df[df[ID_COL] == \"jgh\"].sort_values(TS_COL)\n",
    "freq = pd.infer_freq(g[TS_COL])\n",
    "if not freq:\n",
    "    raise ValueError(\"No inferable frequency after regularization.\")\n",
    "if to_offset(freq).name.lower() != \"h\":\n",
    "    # extra check independent of infer_freq\n",
    "    diffs = g[TS_COL].diff().dropna()\n",
    "    bad = g.loc[diffs != pd.Timedelta(hours=1), TS_COL].head(10).tolist()\n",
    "    raise ValueError(f\"Non-1h gaps remain around: {bad}\")\n",
    "\n",
    "#now use tqdm to iterate through a new forecast every following day starting at 2025-01-01 always at 8am and average out the RMSEs\n",
    "from tqdm.notebook import tqdm\n",
    "rmse_list = []\n",
    "start_date = pd.Timestamp(\"2025-01-01 16:00:00\")\n",
    "end_date = df[TS_COL].max() - pd.Timedelta(hours=8)\n",
    "# end_date = pd.Timestamp(\"2025-02-01 08:00:00\")\n",
    "for _ in tqdm(range((end_date - start_date).days)):\n",
    "    print(start_date)\n",
    "    history_df = df[df[TS_COL] <= start_date]\n",
    "    future_df = hourly_shifts[hourly_shifts['ds'] > start_date].head(8)\n",
    "    future_df['id'] = 'jgh'\n",
    "    forecast_df = pipeline.predict_df(\n",
    "        history_df,\n",
    "        future_df = future_df,\n",
    "        prediction_length=8,\n",
    "        quantile_levels=[0.5],\n",
    "        id_column=ID_COL,\n",
    "        timestamp_column=TS_COL,\n",
    "        target=TARGETS,\n",
    "    )\n",
    "    actuals_df = df[(df[TS_COL] > start_date) & (df[TS_COL] <= start_date + pd.Timedelta(hours=8))]\n",
    "    merged_df = pd.merge(forecast_df, actuals_df, on=[ID_COL, TS_COL], suffixes=('_pred', '_actual'))\n",
    "    rmse = mean_squared_error(\n",
    "        merged_df['total_tbs'],\n",
    "        merged_df['predictions']\n",
    "    )\n",
    "    rmse_list.append(rmse)\n",
    "    start_date += pd.Timedelta(days=1)\n",
    "    #clear output\n",
    "    clear_output(wait=True)\n",
    "average_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Average RMSE over the period: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e183ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-58257dc3-ee55-456d-ad06-e7f8d377cd5e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheduled_shift_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>npi</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>facility_ext_id</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_short_name</th>\n",
       "      <th>shift_start</th>\n",
       "      <th>shift_end</th>\n",
       "      <th>shift_hours</th>\n",
       "      <th>work_start</th>\n",
       "      <th>work_end</th>\n",
       "      <th>work_hours</th>\n",
       "      <th>count_as_shift</th>\n",
       "      <th>is_night</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9021</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joel</td>\n",
       "      <td>Turner</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jewish General Hospital</td>\n",
       "      <td>...</td>\n",
       "      <td>W1</td>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>2021-01-01 16:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1/1/2021 08:00</td>\n",
       "      <td>1/1/2021 16:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9022</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Marton</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jewish General Hospital</td>\n",
       "      <td>...</td>\n",
       "      <td>X1</td>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>2021-01-01 17:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1/1/2021 08:00</td>\n",
       "      <td>1/1/2021 17:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9023</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Will</td>\n",
       "      <td>Grad</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jewish General Hospital</td>\n",
       "      <td>...</td>\n",
       "      <td>X3</td>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>2021-01-01 17:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1/1/2021 08:00</td>\n",
       "      <td>1/1/2021 17:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9025</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>Dankoff</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jewish General Hospital</td>\n",
       "      <td>...</td>\n",
       "      <td>X4</td>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>2021-01-01 16:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1/1/2021 08:00</td>\n",
       "      <td>1/1/2021 16:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9026</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marie Renee</td>\n",
       "      <td>Lajoie</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jewish General Hospital</td>\n",
       "      <td>...</td>\n",
       "      <td>X2</td>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>2021-01-01 16:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1/1/2021 08:00</td>\n",
       "      <td>1/1/2021 16:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58257dc3-ee55-456d-ad06-e7f8d377cd5e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-58257dc3-ee55-456d-ad06-e7f8d377cd5e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-58257dc3-ee55-456d-ad06-e7f8d377cd5e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   scheduled_shift_id  group_id  user_id  employee_id  npi   first_name  \\\n",
       "0                9021         1       40          NaN  NaN         Joel   \n",
       "1                9022         1       52          NaN  NaN      Gregory   \n",
       "2                9023         1       20          NaN  NaN         Will   \n",
       "3                9025         1       17          NaN  NaN        Jerry   \n",
       "4                9026         1       26          NaN  NaN  Marie Renee   \n",
       "\n",
       "  last_name  facility_id  facility_ext_id            facility_name  ...  \\\n",
       "0    Turner            1              NaN  Jewish General Hospital  ...   \n",
       "1    Marton            1              NaN  Jewish General Hospital  ...   \n",
       "2      Grad            1              NaN  Jewish General Hospital  ...   \n",
       "3   Dankoff            1              NaN  Jewish General Hospital  ...   \n",
       "4    Lajoie            1              NaN  Jewish General Hospital  ...   \n",
       "\n",
       "  shift_short_name          shift_start            shift_end shift_hours  \\\n",
       "0               W1  2021-01-01 08:00:00  2021-01-01 16:00:00         8.0   \n",
       "1               X1  2021-01-01 08:00:00  2021-01-01 17:00:00         9.0   \n",
       "2               X3  2021-01-01 08:00:00  2021-01-01 17:00:00         9.0   \n",
       "3               X4  2021-01-01 08:00:00  2021-01-01 16:00:00         8.0   \n",
       "4               X2  2021-01-01 08:00:00  2021-01-01 16:00:00         8.0   \n",
       "\n",
       "       work_start        work_end  work_hours count_as_shift is_night  \\\n",
       "0  1/1/2021 08:00  1/1/2021 16:00         8.0              0        0   \n",
       "1  1/1/2021 08:00  1/1/2021 17:00         9.0              1        0   \n",
       "2  1/1/2021 08:00  1/1/2021 17:00         9.0              1        0   \n",
       "3  1/1/2021 08:00  1/1/2021 16:00         8.0              1        0   \n",
       "4  1/1/2021 08:00  1/1/2021 16:00         8.0              1        0   \n",
       "\n",
       "   is_weekend  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_shifts_df = pd.read_csv('https://www.dropbox.com/scl/fi/yeyr2a7pj6nry8i2q3m0c/all_shifts.csv?rlkey=q1su2h8fqxfnlu7t1l2qe1w0q&raw=1')\n",
    "all_shifts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48ef5fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ds'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3527074891.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#make me a dataframe where each row is an hourly timestamp and columns for each user_id, with the value being the shift type for that user at that timestamp, and fill NaNs with NotWorking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshift_pivot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_shifts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'shift_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NotWorking'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshift_pivot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   9337\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9341\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 ]\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ds'"
     ]
    }
   ],
   "source": [
    "#make me a dataframe where each row is an hourly timestamp and columns for each user_id, with the value being the shift type for that user at that timestamp, and fill NaNs with NotWorking\n",
    "shift_pivot = all_shifts_df.pivot(index='ds', columns='user_id', values='shift_type').fillna('NotWorking')\n",
    "shift_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nptesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
